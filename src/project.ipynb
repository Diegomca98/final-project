{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Status - Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "#import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opendatasets as od\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAS-12 Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Use Kaggle API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to use Kaggle API - Step-by-step guide](https://www.geeksforgeeks.org/how-to-download-kaggle-datasets-into-jupyter-notebook/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since almost all combined CSV files are larger than 60k records and more than 20 columns the best course of action would be to only use one year data, in this case we are going to use the `Combined_Flights_2022.csv` with the shape `(4078318, 61)` and the `Airlines.csv` for labeling if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Data Acquisition - Use Kaggle API** section can be re-run only in case we need to access the data from the kaggle API again. After this section we cleaned the data and saved it as CSV in the `/data/processed/` folder, accessed from there, then we'll create a DB with 2 tables `airlines` and `flights`, with the corresponding data and we'll work the data by retrieving it from the DB tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading flight-delay-dataset-20182022.zip to .\\flight-delay-dataset-20182022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.73G/3.73G [10:20<00:00, 6.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE\n",
    "od.download('https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "def move_folder():\n",
    "    source = './flight-delay-dataset-20182022'\n",
    "    destination = '../data/raw/flight-delay-dataset-20182022'\n",
    "\n",
    "    shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "def remove_unnecesary():\n",
    "    destination = '../data/raw/flight-delay-dataset-20182022'\n",
    "    shutil.rmtree(os.path.join(destination, 'raw'))\n",
    "    \n",
    "    files = [x for x in os.listdir(destination) if not ('2022.csv' in x or 'Airlines' in x)]\n",
    "    for f in files:\n",
    "        os.remove(os.path.join(destination, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "move_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../data/raw/flight-delay-dataset-20182022\\\\raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ONLY RUN ONCE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mremove_unnecesary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mremove_unnecesary\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_unnecesary\u001b[39m():\n\u001b[0;32m      3\u001b[0m     destination \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/raw/flight-delay-dataset-20182022\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     files \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(destination) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirlines\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x)]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:787\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:615\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    613\u001b[0m         entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(scandir_it)\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 615\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m     entries \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:612\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rmtree_unsafe\u001b[39m(path, onerror):\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 612\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m scandir_it:\n\u001b[0;32m    613\u001b[0m             entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(scandir_it)\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../data/raw/flight-delay-dataset-20182022\\\\raw'"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE\n",
    "remove_unnecesary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "for file in os.listdir('../data/raw/flight-delay-dataset-20182022'):\n",
    "    shutil.move(os.path.join('../data/raw/flight-delay-dataset-20182022/', file), os.path.join('../data/processed'), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Clean and Store Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/Combined_Flights_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4078318 entries, 0 to 4078317\n",
      "Data columns (total 61 columns):\n",
      " #   Column                                   Dtype  \n",
      "---  ------                                   -----  \n",
      " 0   FlightDate                               object \n",
      " 1   Airline                                  object \n",
      " 2   Origin                                   object \n",
      " 3   Dest                                     object \n",
      " 4   Cancelled                                bool   \n",
      " 5   Diverted                                 bool   \n",
      " 6   CRSDepTime                               int64  \n",
      " 7   DepTime                                  float64\n",
      " 8   DepDelayMinutes                          float64\n",
      " 9   DepDelay                                 float64\n",
      " 10  ArrTime                                  float64\n",
      " 11  ArrDelayMinutes                          float64\n",
      " 12  AirTime                                  float64\n",
      " 13  CRSElapsedTime                           float64\n",
      " 14  ActualElapsedTime                        float64\n",
      " 15  Distance                                 float64\n",
      " 16  Year                                     int64  \n",
      " 17  Quarter                                  int64  \n",
      " 18  Month                                    int64  \n",
      " 19  DayofMonth                               int64  \n",
      " 20  DayOfWeek                                int64  \n",
      " 21  Marketing_Airline_Network                object \n",
      " 22  Operated_or_Branded_Code_Share_Partners  object \n",
      " 23  DOT_ID_Marketing_Airline                 int64  \n",
      " 24  IATA_Code_Marketing_Airline              object \n",
      " 25  Flight_Number_Marketing_Airline          int64  \n",
      " 26  Operating_Airline                        object \n",
      " 27  DOT_ID_Operating_Airline                 int64  \n",
      " 28  IATA_Code_Operating_Airline              object \n",
      " 29  Tail_Number                              object \n",
      " 30  Flight_Number_Operating_Airline          int64  \n",
      " 31  OriginAirportID                          int64  \n",
      " 32  OriginAirportSeqID                       int64  \n",
      " 33  OriginCityMarketID                       int64  \n",
      " 34  OriginCityName                           object \n",
      " 35  OriginState                              object \n",
      " 36  OriginStateFips                          int64  \n",
      " 37  OriginStateName                          object \n",
      " 38  OriginWac                                int64  \n",
      " 39  DestAirportID                            int64  \n",
      " 40  DestAirportSeqID                         int64  \n",
      " 41  DestCityMarketID                         int64  \n",
      " 42  DestCityName                             object \n",
      " 43  DestState                                object \n",
      " 44  DestStateFips                            int64  \n",
      " 45  DestStateName                            object \n",
      " 46  DestWac                                  int64  \n",
      " 47  DepDel15                                 float64\n",
      " 48  DepartureDelayGroups                     float64\n",
      " 49  DepTimeBlk                               object \n",
      " 50  TaxiOut                                  float64\n",
      " 51  WheelsOff                                float64\n",
      " 52  WheelsOn                                 float64\n",
      " 53  TaxiIn                                   float64\n",
      " 54  CRSArrTime                               int64  \n",
      " 55  ArrDelay                                 float64\n",
      " 56  ArrDel15                                 float64\n",
      " 57  ArrivalDelayGroups                       float64\n",
      " 58  ArrTimeBlk                               object \n",
      " 59  DistanceGroup                            int64  \n",
      " 60  DivAirportLandings                       int64  \n",
      "dtypes: bool(2), float64(18), int64(23), object(18)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>WheelsOff</th>\n",
       "      <th>WheelsOn</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrDel15</th>\n",
       "      <th>ArrivalDelayGroups</th>\n",
       "      <th>DistanceGroup</th>\n",
       "      <th>DivAirportLandings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>3.957885e+06</td>\n",
       "      <td>3.957823e+06</td>\n",
       "      <td>3.957823e+06</td>\n",
       "      <td>3.954079e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.955652e+06</td>\n",
       "      <td>3.955652e+06</td>\n",
       "      <td>3.954076e+06</td>\n",
       "      <td>3.954076e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.329587e+03</td>\n",
       "      <td>1.334374e+03</td>\n",
       "      <td>1.601494e+01</td>\n",
       "      <td>1.309049e+01</td>\n",
       "      <td>1.457886e+03</td>\n",
       "      <td>1.578307e+01</td>\n",
       "      <td>1.110075e+02</td>\n",
       "      <td>1.413211e+02</td>\n",
       "      <td>1.358624e+02</td>\n",
       "      <td>7.978657e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.697375e+01</td>\n",
       "      <td>1.356576e+03</td>\n",
       "      <td>1.455073e+03</td>\n",
       "      <td>7.894387e+00</td>\n",
       "      <td>1.486058e+03</td>\n",
       "      <td>7.528486e+00</td>\n",
       "      <td>2.164715e-01</td>\n",
       "      <td>-6.256103e-02</td>\n",
       "      <td>3.663516e+00</td>\n",
       "      <td>3.685098e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.904801e+02</td>\n",
       "      <td>5.056219e+02</td>\n",
       "      <td>5.231498e+01</td>\n",
       "      <td>5.332016e+01</td>\n",
       "      <td>5.431841e+02</td>\n",
       "      <td>5.198424e+01</td>\n",
       "      <td>6.996246e+01</td>\n",
       "      <td>7.179635e+01</td>\n",
       "      <td>7.185501e+01</td>\n",
       "      <td>5.914742e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.495407e+00</td>\n",
       "      <td>5.075580e+02</td>\n",
       "      <td>5.378428e+02</td>\n",
       "      <td>6.663118e+00</td>\n",
       "      <td>5.185078e+02</td>\n",
       "      <td>5.524625e+01</td>\n",
       "      <td>4.118393e-01</td>\n",
       "      <td>2.487442e+00</td>\n",
       "      <td>2.320848e+00</td>\n",
       "      <td>1.141331e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.800000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>-4.800000e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.140000e+02</td>\n",
       "      <td>9.170000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>1.046000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>3.680000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>9.320000e+02</td>\n",
       "      <td>1.044000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.103000e+03</td>\n",
       "      <td>-1.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.320000e+03</td>\n",
       "      <td>1.325000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>1.500000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.400000e+01</td>\n",
       "      <td>1.240000e+02</td>\n",
       "      <td>1.190000e+02</td>\n",
       "      <td>6.430000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.338000e+03</td>\n",
       "      <td>1.456000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.513000e+03</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.735000e+03</td>\n",
       "      <td>1.744000e+03</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.914000e+03</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.410000e+02</td>\n",
       "      <td>1.710000e+02</td>\n",
       "      <td>1.670000e+02</td>\n",
       "      <td>1.035000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.758000e+03</td>\n",
       "      <td>1.909000e+03</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.920000e+03</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.359000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>7.223000e+03</td>\n",
       "      <td>7.223000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>7.232000e+03</td>\n",
       "      <td>7.270000e+02</td>\n",
       "      <td>6.900000e+02</td>\n",
       "      <td>7.640000e+02</td>\n",
       "      <td>5.095000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.210000e+02</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.900000e+02</td>\n",
       "      <td>2.359000e+03</td>\n",
       "      <td>7.232000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRSDepTime       DepTime  DepDelayMinutes      DepDelay  \\\n",
       "count  4.078318e+06  3.957885e+06     3.957823e+06  3.957823e+06   \n",
       "mean   1.329587e+03  1.334374e+03     1.601494e+01  1.309049e+01   \n",
       "std    4.904801e+02  5.056219e+02     5.231498e+01  5.332016e+01   \n",
       "min    1.000000e+00  1.000000e+00     0.000000e+00 -7.800000e+01   \n",
       "25%    9.140000e+02  9.170000e+02     0.000000e+00 -5.000000e+00   \n",
       "50%    1.320000e+03  1.325000e+03     0.000000e+00 -2.000000e+00   \n",
       "75%    1.735000e+03  1.744000e+03     1.100000e+01  1.100000e+01   \n",
       "max    2.359000e+03  2.400000e+03     7.223000e+03  7.223000e+03   \n",
       "\n",
       "            ArrTime  ArrDelayMinutes       AirTime  CRSElapsedTime  \\\n",
       "count  3.954079e+06     3.944916e+06  3.944916e+06    4.078318e+06   \n",
       "mean   1.457886e+03     1.578307e+01  1.110075e+02    1.413211e+02   \n",
       "std    5.431841e+02     5.198424e+01  6.996246e+01    7.179635e+01   \n",
       "min    1.000000e+00     0.000000e+00  8.000000e+00   -4.800000e+01   \n",
       "25%    1.046000e+03     0.000000e+00  6.000000e+01    8.900000e+01   \n",
       "50%    1.500000e+03     0.000000e+00  9.400000e+01    1.240000e+02   \n",
       "75%    1.914000e+03     1.000000e+01  1.410000e+02    1.710000e+02   \n",
       "max    2.400000e+03     7.232000e+03  7.270000e+02    6.900000e+02   \n",
       "\n",
       "       ActualElapsedTime      Distance  ...       TaxiOut     WheelsOff  \\\n",
       "count       3.944916e+06  4.078318e+06  ...  3.955652e+06  3.955652e+06   \n",
       "mean        1.358624e+02  7.978657e+02  ...  1.697375e+01  1.356576e+03   \n",
       "std         7.185501e+01  5.914742e+02  ...  9.495407e+00  5.075580e+02   \n",
       "min         1.400000e+01  3.100000e+01  ...  1.000000e+00  1.000000e+00   \n",
       "25%         8.300000e+01  3.680000e+02  ...  1.100000e+01  9.320000e+02   \n",
       "50%         1.190000e+02  6.430000e+02  ...  1.500000e+01  1.338000e+03   \n",
       "75%         1.670000e+02  1.035000e+03  ...  1.900000e+01  1.758000e+03   \n",
       "max         7.640000e+02  5.095000e+03  ...  2.210000e+02  2.400000e+03   \n",
       "\n",
       "           WheelsOn        TaxiIn    CRSArrTime      ArrDelay      ArrDel15  \\\n",
       "count  3.954076e+06  3.954076e+06  4.078318e+06  3.944916e+06  3.944916e+06   \n",
       "mean   1.455073e+03  7.894387e+00  1.486058e+03  7.528486e+00  2.164715e-01   \n",
       "std    5.378428e+02  6.663118e+00  5.185078e+02  5.524625e+01  4.118393e-01   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00 -1.000000e+02  0.000000e+00   \n",
       "25%    1.044000e+03  4.000000e+00  1.103000e+03 -1.400000e+01  0.000000e+00   \n",
       "50%    1.456000e+03  6.000000e+00  1.513000e+03 -5.000000e+00  0.000000e+00   \n",
       "75%    1.909000e+03  9.000000e+00  1.920000e+03  1.000000e+01  0.000000e+00   \n",
       "max    2.400000e+03  2.900000e+02  2.359000e+03  7.232000e+03  1.000000e+00   \n",
       "\n",
       "       ArrivalDelayGroups  DistanceGroup  DivAirportLandings  \n",
       "count        3.944916e+06   4.078318e+06        4.078318e+06  \n",
       "mean        -6.256103e-02   3.663516e+00        3.685098e-03  \n",
       "std          2.487442e+00   2.320848e+00        1.141331e-01  \n",
       "min         -2.000000e+00   1.000000e+00        0.000000e+00  \n",
       "25%         -1.000000e+00   2.000000e+00        0.000000e+00  \n",
       "50%         -1.000000e+00   3.000000e+00        0.000000e+00  \n",
       "75%          0.000000e+00   5.000000e+00        0.000000e+00  \n",
       "max          1.200000e+01   1.100000e+01        9.000000e+00  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nulls(df):\n",
    "    # Assuming df is your DataFrame\n",
    "    # Check for null values in each column\n",
    "    percentage = 10\n",
    "    percent = (percentage * len(df)) / 100\n",
    "    null_counts = df.isnull().sum()\n",
    "\n",
    "    # Filter columns with null values and print their sum\n",
    "    columns_with_nulls_ten = null_counts[null_counts > percent]\n",
    "    columns_with_nulls = null_counts[null_counts > 0]\n",
    "    if len(columns_with_nulls_ten) > 0:\n",
    "        for column, count in columns_with_nulls.items():\n",
    "            print(f\"Column '{column}' has {count} null values.\")\n",
    "    else:\n",
    "        print(\"The null values in the dataframe don't exceed {percent} values or {percentage}% of the total data\".format(percent=percent, percentage=percentage))\n",
    "        print(\"Depending on Duplicated values we might want to consider dropping them since that low percentage of null values would hardly make any difference in the EDA or the model creation and prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null values in the dataframe don't exceed 407831.8 values or 10% of the total data\n",
      "Depending on Duplicated values we might want to consider dropping them since that low percentage of null values would hardly make any difference in the EDA or the model creation and prediction\n"
     ]
    }
   ],
   "source": [
    "check_nulls(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques = data.IATA_Code_Operating_Airline.unique()\n",
    "len(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = data[['OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac']]\n",
    "origins.drop_duplicates(inplace=True)\n",
    "origins.to_csv('../data/processed/origins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = data[['DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac']]\n",
    "destinations.drop_duplicates(inplace=True)\n",
    "destinations.to_csv('../data/processed/destinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['CRSDepTime','ActualElapsedTime','CRSArrTime', 'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac', 'TaxiIn', 'TaxiOut', 'ArrDel15', 'ArrivalDelayGroups', 'ArrTimeBlk', 'DistanceGroup', 'CRSDepTime', 'DepDel15', 'DepartureDelayGroups', 'DepTimeBlk', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'CRSArrTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_nulls(value):\n",
    "    if pd.isnull(value):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(value)\n",
    "    \n",
    "# Define a function to transform values\n",
    "def transform_time(value):\n",
    "    if isinstance(value, int):\n",
    "        value = str(value)  # Convert integer to string\n",
    "    value = value.zfill(4)  # Pad with leading zeros if necessary\n",
    "    if len(value) == 4:\n",
    "        if int(value) == 2400:\n",
    "            return '00:00'\n",
    "        if int(value) < 10:  # For values less than 10\n",
    "            return f'00:0{value[0]}'\n",
    "        elif int(value) < 100:  # For values between 10 and 100\n",
    "            return f'00:{value[:2]}'\n",
    "        else:  # For values over 100\n",
    "            return f'{value[:2]}:{value[2:]}'\n",
    "    else:\n",
    "        return value[:2] + ':' + value[2:]  # Format as 'HH:MM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dates():\n",
    "    data['FlightDate'] = pd.to_datetime(data['FlightDate'])\n",
    "\n",
    "    # Format time WheelsOff\n",
    "    data['WheelsOff'] = data['WheelsOff'].apply(treat_nulls)\n",
    "    data['WheelsOff'] = data['WheelsOff'].apply(transform_time)\n",
    "    data['WheelsOff'] = pd.to_datetime(data['WheelsOff'], format='%H:%M').dt.time\n",
    "\n",
    "    # Format time WheelsOn\n",
    "    data['WheelsOn'] = data['WheelsOn'].apply(treat_nulls)\n",
    "    data['WheelsOn'] = data['WheelsOn'].apply(transform_time)\n",
    "    data['WheelsOn'] = pd.to_datetime(data['WheelsOn'], format='%H:%M').dt.time\n",
    "\n",
    "    # Format time ArrTime\n",
    "    data['ArrTime'] = data['ArrTime'].apply(treat_nulls)\n",
    "    data['ArrTime'] = data['ArrTime'].apply(transform_time)\n",
    "    data['ArrTime'] = pd.to_datetime(data['ArrTime'], format='%H:%M').dt.time\n",
    "\n",
    "\n",
    "    # Format time DepTime\n",
    "    data['DepTime'] = data['DepTime'].apply(treat_nulls)\n",
    "    data['DepTime'] = data['DepTime'].apply(transform_time)\n",
    "    data['DepTime'] = pd.to_datetime(data['DepTime'], format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FlightDate', 'Airline', 'Cancelled', 'Diverted', 'DepTime',\n",
      "       'DepDelayMinutes', 'DepDelay', 'ArrTime', 'ArrDelayMinutes', 'AirTime',\n",
      "       'CRSElapsedTime', 'Distance', 'Year', 'Quarter', 'Month', 'DayofMonth',\n",
      "       'DayOfWeek', 'Marketing_Airline_Network',\n",
      "       'Operated_or_Branded_Code_Share_Partners', 'DOT_ID_Marketing_Airline',\n",
      "       'IATA_Code_Marketing_Airline', 'Flight_Number_Marketing_Airline',\n",
      "       'Operating_Airline', 'DOT_ID_Operating_Airline',\n",
      "       'IATA_Code_Operating_Airline', 'Tail_Number',\n",
      "       'Flight_Number_Operating_Airline', 'OriginAirportID', 'DestAirportID',\n",
      "       'WheelsOff', 'WheelsOn', 'ArrDelay', 'DivAirportLandings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "colms = data.columns\n",
    "\n",
    "print(colms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_nulls(value):\n",
    "    if pd.isnull(value):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(value)\n",
    "    \n",
    "# Define a function to transform values\n",
    "def transform_time(value):\n",
    "    if isinstance(value, int):\n",
    "        value = str(value)  # Convert integer to string\n",
    "    value = value.zfill(4)  # Pad with leading zeros if necessary\n",
    "    if len(value) == 4:\n",
    "        if int(value) == 2400:\n",
    "            return '00:00'\n",
    "        if int(value) < 10:  # For values less than 10\n",
    "            return f'00:0{value[0]}'\n",
    "        elif int(value) < 100:  # For values between 10 and 100\n",
    "            return f'00:{value[:2]}'\n",
    "        else:  # For values over 100\n",
    "            return f'{value[:2]}:{value[2:]}'\n",
    "    else:\n",
    "        return value[:2] + ':' + value[2:]  # Format as 'HH:MM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dates():\n",
    "    data['FlightDate'] = pd.to_datetime(data['FlightDate'])\n",
    "\n",
    "    # Format time WheelsOff\n",
    "    data['WheelsOff'] = data['WheelsOff'].apply(treat_nulls)\n",
    "    data['WheelsOff'] = data['WheelsOff'].apply(transform_time)\n",
    "    data['WheelsOff'] = pd.to_datetime(data['WheelsOff'], format='%H:%M').dt.time\n",
    "\n",
    "    # Format time WheelsOn\n",
    "    data['WheelsOn'] = data['WheelsOn'].apply(treat_nulls)\n",
    "    data['WheelsOn'] = data['WheelsOn'].apply(transform_time)\n",
    "    data['WheelsOn'] = pd.to_datetime(data['WheelsOn'], format='%H:%M').dt.time\n",
    "\n",
    "    # Format time ArrTime\n",
    "    data['ArrTime'] = data['ArrTime'].apply(treat_nulls)\n",
    "    data['ArrTime'] = data['ArrTime'].apply(transform_time)\n",
    "    data['ArrTime'] = pd.to_datetime(data['ArrTime'], format='%H:%M').dt.time\n",
    "\n",
    "\n",
    "    # Format time DepTime\n",
    "    data['DepTime'] = data['DepTime'].apply(treat_nulls)\n",
    "    data['DepTime'] = data['DepTime'].apply(transform_time)\n",
    "    data['DepTime'] = pd.to_datetime(data['DepTime'], format='%H:%M').dt.time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'datetime.time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mformat_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m, in \u001b[0;36mformat_dates\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlightDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlightDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Format time WheelsOff\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWheelsOff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreat_nulls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(transform_time)\n\u001b[0;32m      7\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtime\n",
      "File \u001b[1;32md:\\Documents\\courses\\flight-status-prediction\\.env-flights\\Lib\\site-packages\\pandas\\core\\series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Documents\\courses\\flight-status-prediction\\.env-flights\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Documents\\courses\\flight-status-prediction\\.env-flights\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32md:\\Documents\\courses\\flight-status-prediction\\.env-flights\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Documents\\courses\\flight-status-prediction\\.env-flights\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[50], line 5\u001b[0m, in \u001b[0;36mtreat_nulls\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'datetime.time'"
     ]
    }
   ],
   "source": [
    "format_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/processed/Combined_Flights_2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.to_csv('../data/processed/Combined_Flights_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a bussines perspective point of view I wouldn't impute null values, since, for example, DepTime might be null because the flight might have been cancelled and if we impute or drop that registry we might affect the future predictions or even the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Database Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# load the .env file variables\n",
    "load_dotenv()\n",
    "\n",
    "# 1) Connect to the database here using the SQLAlchemy's create_engine function\n",
    "def conn_string():\n",
    "    user = os.getenv('DB_USER')\n",
    "    pwd = os.getenv('DB_PASSWORD')\n",
    "    host = os.getenv('DB_HOST')\n",
    "    db = os.getenv('DB_NAME')\n",
    "\n",
    "    return f\"postgresql://{user}:{pwd}@{host}/{db}\"\n",
    "\n",
    "def connect():\n",
    "    global engine\n",
    "    print(\"Starting connection...\")\n",
    "    engine = create_engine(conn_string()).execution_options(autocommit=True)\n",
    "    engine.connect()\n",
    "\n",
    "    return engine\n",
    "\n",
    "connect()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Define your dataset columns and their corresponding data types\n",
    "columns = {\n",
    "    'FlightDate': 'DATE',\n",
    "    'Airline': 'VARCHAR(255)',\n",
    "    'Origin': 'VARCHAR(255)',\n",
    "    # Define other columns and their data types here\n",
    "}\n",
    "\n",
    "# Generate SQL statement to create table\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE flights (\n",
    "    {\", \".join([f\"{col} {dtype}\" for col, dtype in columns.items()])}\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL statement to create table\n",
    "engine.execute(create_table_sql)\n",
    "\n",
    "# Now, let's say you have your data stored in a pandas DataFrame called 'df'\n",
    "# You can iterate over the DataFrame rows and generate SQL statements to insert data\n",
    "for index, row in df.iterrows():\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO flights ({\", \".join(columns.keys())}) VALUES \n",
    "    ({\", \".join([str(row[col]) for col in columns.keys()])});\n",
    "    \"\"\"\n",
    "    # Execute SQL statement to insert data\n",
    "    engine.execute(insert_sql)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# 4) Use pandas to print one of the tables as dataframes using read_sql function\n",
    "df = pd.read_sql('SELECT * FROM authors', engine)\n",
    "print(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load_dotenv()\n",
    "\n",
    "# 1) Connect to the database here using the SQLAlchemy's create_engine function\n",
    "def conn_string():\n",
    "    user = os.getenv('DB_USER')\n",
    "    pwd = os.getenv('DB_PASSWORD')\n",
    "    host = os.getenv('DB_HOST')\n",
    "    db = os.getenv('DB_NAME')\n",
    "\n",
    "    return f\"postgresql://{user}:{pwd}@{host}/{db}\"\n",
    "\n",
    "def connect():\n",
    "    global engine\n",
    "    print(\"Starting connection...\")\n",
    "    engine = create_engine(conn_string()).execution_options(autocommit=True)\n",
    "    engine.connect()\n",
    "\n",
    "    return engine\n",
    "\n",
    "connect()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Queries to obtain the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-flights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
