{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Status - Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "#import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opendatasets as od\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAS-12 Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Use Kaggle API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to use Kaggle API - Step-by-step guide](https://www.geeksforgeeks.org/how-to-download-kaggle-datasets-into-jupyter-notebook/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since almost all combined CSV files are larger than 60k records and more than 20 columns the best course of action would be to only use one year data, in this case we are going to use the `Combined_Flights_2022.csv` with the shape `(4078318, 61)` and the `Airlines.csv` for labeling if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Data Acquisition - Use Kaggle API** section can be re-run only in case we need to access the data from the kaggle API again. After this section we cleaned the data and saved it as CSV in the `/data/processed/` folder, accessed from there, then we'll create a DB with 2 tables `airlines` and `flights`, with the corresponding data and we'll work the data by retrieving it from the DB tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading flight-delay-dataset-20182022.zip to .\\flight-delay-dataset-20182022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.73G/3.73G [01:49<00:00, 36.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE\n",
    "od.download('https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "def move_folder():\n",
    "    source = './flight-delay-dataset-20182022'\n",
    "    destination = '../data/raw/flight-delay-dataset-20182022'\n",
    "\n",
    "    shutil.move(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "def remove_unnecesary():\n",
    "    destination = '../data/raw/flight-delay-dataset-20182022'\n",
    "    try:\n",
    "        shutil.rmtree(os.path.join(destination, 'raw'))\n",
    "    except:\n",
    "        print(\"Continue\")\n",
    "    finally:\n",
    "        files = [x for x in os.listdir(destination) if not ('2022.csv' in x or 'Airlines' in x)]\n",
    "        for f in files:\n",
    "            os.remove(os.path.join(destination, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "move_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Acceso denegado: '../data/raw/flight-delay-dataset-20182022\\\\flight-delay-dataset-20182022'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ONLY RUN ONCE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mremove_unnecesary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[68], line 11\u001b[0m, in \u001b[0;36mremove_unnecesary\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m files \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(destination) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAirlines\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x)]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Acceso denegado: '../data/raw/flight-delay-dataset-20182022\\\\flight-delay-dataset-20182022'"
     ]
    }
   ],
   "source": [
    "# ONLY RUN ONCE\n",
    "remove_unnecesary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "for file in os.listdir('../data/raw/flight-delay-dataset-20182022'):\n",
    "    shutil.move(os.path.join('../data/raw/flight-delay-dataset-20182022/', file), os.path.join('../data/processed'), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Clean and Store Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/Combined_Flights_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4078318 entries, 0 to 4078317\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                   Dtype  \n",
      "---  ------                                   -----  \n",
      " 0   Unnamed: 0                               int64  \n",
      " 1   FlightDate                               object \n",
      " 2   Airline                                  object \n",
      " 3   Cancelled                                bool   \n",
      " 4   Diverted                                 bool   \n",
      " 5   DepTime                                  object \n",
      " 6   DepDelayMinutes                          float64\n",
      " 7   DepDelay                                 float64\n",
      " 8   ArrTime                                  object \n",
      " 9   ArrDelayMinutes                          float64\n",
      " 10  AirTime                                  float64\n",
      " 11  CRSElapsedTime                           float64\n",
      " 12  Distance                                 float64\n",
      " 13  Year                                     int64  \n",
      " 14  Quarter                                  int64  \n",
      " 15  Month                                    int64  \n",
      " 16  DayofMonth                               int64  \n",
      " 17  DayOfWeek                                int64  \n",
      " 18  Marketing_Airline_Network                object \n",
      " 19  Operated_or_Branded_Code_Share_Partners  object \n",
      " 20  DOT_ID_Marketing_Airline                 int64  \n",
      " 21  IATA_Code_Marketing_Airline              object \n",
      " 22  Flight_Number_Marketing_Airline          int64  \n",
      " 23  Operating_Airline                        object \n",
      " 24  DOT_ID_Operating_Airline                 int64  \n",
      " 25  IATA_Code_Operating_Airline              object \n",
      " 26  Tail_Number                              object \n",
      " 27  Flight_Number_Operating_Airline          int64  \n",
      " 28  OriginAirportID                          int64  \n",
      " 29  DestAirportID                            int64  \n",
      " 30  WheelsOff                                object \n",
      " 31  WheelsOn                                 object \n",
      " 32  ArrDelay                                 float64\n",
      " 33  DivAirportLandings                       int64  \n",
      "dtypes: bool(2), float64(7), int64(13), object(12)\n",
      "memory usage: 1003.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DOT_ID_Marketing_Airline</th>\n",
       "      <th>Flight_Number_Marketing_Airline</th>\n",
       "      <th>DOT_ID_Operating_Airline</th>\n",
       "      <th>Flight_Number_Operating_Airline</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>DestAirportID</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DivAirportLandings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>3.957823e+06</td>\n",
       "      <td>3.957823e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4078318.0</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "      <td>3.944916e+06</td>\n",
       "      <td>4.078318e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.039158e+06</td>\n",
       "      <td>1.601494e+01</td>\n",
       "      <td>1.309049e+01</td>\n",
       "      <td>1.578307e+01</td>\n",
       "      <td>1.110075e+02</td>\n",
       "      <td>1.413211e+02</td>\n",
       "      <td>7.978657e+02</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>1.741207e+00</td>\n",
       "      <td>4.083803e+00</td>\n",
       "      <td>1.571131e+01</td>\n",
       "      <td>4.005566e+00</td>\n",
       "      <td>1.983101e+04</td>\n",
       "      <td>2.562115e+03</td>\n",
       "      <td>1.999122e+04</td>\n",
       "      <td>2.562145e+03</td>\n",
       "      <td>1.265994e+04</td>\n",
       "      <td>1.265990e+04</td>\n",
       "      <td>7.528486e+00</td>\n",
       "      <td>3.685098e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.177309e+06</td>\n",
       "      <td>5.231498e+01</td>\n",
       "      <td>5.332016e+01</td>\n",
       "      <td>5.198424e+01</td>\n",
       "      <td>6.996246e+01</td>\n",
       "      <td>7.179635e+01</td>\n",
       "      <td>5.914742e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.037563e-01</td>\n",
       "      <td>1.998918e+00</td>\n",
       "      <td>8.760122e+00</td>\n",
       "      <td>2.007050e+00</td>\n",
       "      <td>2.760907e+02</td>\n",
       "      <td>1.745826e+03</td>\n",
       "      <td>3.767694e+02</td>\n",
       "      <td>1.745873e+03</td>\n",
       "      <td>1.522713e+03</td>\n",
       "      <td>1.522718e+03</td>\n",
       "      <td>5.524625e+01</td>\n",
       "      <td>1.141331e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-7.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>-4.800000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.939300e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.939300e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.013500e+04</td>\n",
       "      <td>1.013500e+04</td>\n",
       "      <td>-1.000000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.019579e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>3.680000e+02</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.979000e+04</td>\n",
       "      <td>1.105000e+03</td>\n",
       "      <td>1.979000e+04</td>\n",
       "      <td>1.105000e+03</td>\n",
       "      <td>1.129200e+04</td>\n",
       "      <td>1.129200e+04</td>\n",
       "      <td>-1.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.039158e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.400000e+01</td>\n",
       "      <td>1.240000e+02</td>\n",
       "      <td>6.430000e+02</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.980500e+04</td>\n",
       "      <td>2.228000e+03</td>\n",
       "      <td>1.997700e+04</td>\n",
       "      <td>2.228000e+03</td>\n",
       "      <td>1.288900e+04</td>\n",
       "      <td>1.288900e+04</td>\n",
       "      <td>-5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.058738e+06</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.410000e+02</td>\n",
       "      <td>1.710000e+02</td>\n",
       "      <td>1.035000e+03</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.997700e+04</td>\n",
       "      <td>3.877000e+03</td>\n",
       "      <td>2.037800e+04</td>\n",
       "      <td>3.877000e+03</td>\n",
       "      <td>1.402700e+04</td>\n",
       "      <td>1.402700e+04</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.078317e+06</td>\n",
       "      <td>7.223000e+03</td>\n",
       "      <td>7.223000e+03</td>\n",
       "      <td>7.232000e+03</td>\n",
       "      <td>7.270000e+02</td>\n",
       "      <td>6.900000e+02</td>\n",
       "      <td>5.095000e+03</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.043600e+04</td>\n",
       "      <td>9.680000e+03</td>\n",
       "      <td>2.050000e+04</td>\n",
       "      <td>9.680000e+03</td>\n",
       "      <td>1.686900e+04</td>\n",
       "      <td>1.686900e+04</td>\n",
       "      <td>7.232000e+03</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  DepDelayMinutes      DepDelay  ArrDelayMinutes  \\\n",
       "count  4.078318e+06     3.957823e+06  3.957823e+06     3.944916e+06   \n",
       "mean   2.039158e+06     1.601494e+01  1.309049e+01     1.578307e+01   \n",
       "std    1.177309e+06     5.231498e+01  5.332016e+01     5.198424e+01   \n",
       "min    0.000000e+00     0.000000e+00 -7.800000e+01     0.000000e+00   \n",
       "25%    1.019579e+06     0.000000e+00 -5.000000e+00     0.000000e+00   \n",
       "50%    2.039158e+06     0.000000e+00 -2.000000e+00     0.000000e+00   \n",
       "75%    3.058738e+06     1.100000e+01  1.100000e+01     1.000000e+01   \n",
       "max    4.078317e+06     7.223000e+03  7.223000e+03     7.232000e+03   \n",
       "\n",
       "            AirTime  CRSElapsedTime      Distance       Year       Quarter  \\\n",
       "count  3.944916e+06    4.078318e+06  4.078318e+06  4078318.0  4.078318e+06   \n",
       "mean   1.110075e+02    1.413211e+02  7.978657e+02     2022.0  1.741207e+00   \n",
       "std    6.996246e+01    7.179635e+01  5.914742e+02        0.0  7.037563e-01   \n",
       "min    8.000000e+00   -4.800000e+01  3.100000e+01     2022.0  1.000000e+00   \n",
       "25%    6.000000e+01    8.900000e+01  3.680000e+02     2022.0  1.000000e+00   \n",
       "50%    9.400000e+01    1.240000e+02  6.430000e+02     2022.0  2.000000e+00   \n",
       "75%    1.410000e+02    1.710000e+02  1.035000e+03     2022.0  2.000000e+00   \n",
       "max    7.270000e+02    6.900000e+02  5.095000e+03     2022.0  3.000000e+00   \n",
       "\n",
       "              Month    DayofMonth     DayOfWeek  DOT_ID_Marketing_Airline  \\\n",
       "count  4.078318e+06  4.078318e+06  4.078318e+06              4.078318e+06   \n",
       "mean   4.083803e+00  1.571131e+01  4.005566e+00              1.983101e+04   \n",
       "std    1.998918e+00  8.760122e+00  2.007050e+00              2.760907e+02   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00              1.939300e+04   \n",
       "25%    2.000000e+00  8.000000e+00  2.000000e+00              1.979000e+04   \n",
       "50%    4.000000e+00  1.600000e+01  4.000000e+00              1.980500e+04   \n",
       "75%    6.000000e+00  2.300000e+01  6.000000e+00              1.997700e+04   \n",
       "max    7.000000e+00  3.100000e+01  7.000000e+00              2.043600e+04   \n",
       "\n",
       "       Flight_Number_Marketing_Airline  DOT_ID_Operating_Airline  \\\n",
       "count                     4.078318e+06              4.078318e+06   \n",
       "mean                      2.562115e+03              1.999122e+04   \n",
       "std                       1.745826e+03              3.767694e+02   \n",
       "min                       1.000000e+00              1.939300e+04   \n",
       "25%                       1.105000e+03              1.979000e+04   \n",
       "50%                       2.228000e+03              1.997700e+04   \n",
       "75%                       3.877000e+03              2.037800e+04   \n",
       "max                       9.680000e+03              2.050000e+04   \n",
       "\n",
       "       Flight_Number_Operating_Airline  OriginAirportID  DestAirportID  \\\n",
       "count                     4.078318e+06     4.078318e+06   4.078318e+06   \n",
       "mean                      2.562145e+03     1.265994e+04   1.265990e+04   \n",
       "std                       1.745873e+03     1.522713e+03   1.522718e+03   \n",
       "min                       1.000000e+00     1.013500e+04   1.013500e+04   \n",
       "25%                       1.105000e+03     1.129200e+04   1.129200e+04   \n",
       "50%                       2.228000e+03     1.288900e+04   1.288900e+04   \n",
       "75%                       3.877000e+03     1.402700e+04   1.402700e+04   \n",
       "max                       9.680000e+03     1.686900e+04   1.686900e+04   \n",
       "\n",
       "           ArrDelay  DivAirportLandings  \n",
       "count  3.944916e+06        4.078318e+06  \n",
       "mean   7.528486e+00        3.685098e-03  \n",
       "std    5.524625e+01        1.141331e-01  \n",
       "min   -1.000000e+02        0.000000e+00  \n",
       "25%   -1.400000e+01        0.000000e+00  \n",
       "50%   -5.000000e+00        0.000000e+00  \n",
       "75%    1.000000e+01        0.000000e+00  \n",
       "max    7.232000e+03        9.000000e+00  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nulls(df):\n",
    "    # Assuming df is your DataFrame\n",
    "    # Check for null values in each column\n",
    "    percentage = 10\n",
    "    percent = (percentage * len(df)) / 100\n",
    "    null_counts = df.isnull().sum()\n",
    "\n",
    "    # Filter columns with null values and print their sum\n",
    "    columns_with_nulls_ten = null_counts[null_counts > percent]\n",
    "    columns_with_nulls = null_counts[null_counts > 0]\n",
    "    if len(columns_with_nulls_ten) > 0:\n",
    "        for column, count in columns_with_nulls.items():\n",
    "            print(f\"Column '{column}' has {count} null values.\")\n",
    "    else:\n",
    "        print(\"The null values in the dataframe don't exceed {percent} values or {percentage}% of the total data\".format(percent=percent, percentage=percentage))\n",
    "        print(\"Depending on Duplicated values we might want to consider dropping them since that low percentage of null values would hardly make any difference in the EDA or the model creation and prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null values in the dataframe don't exceed 407831.8 values or 10% of the total data\n",
      "Depending on Duplicated values we might want to consider dropping them since that low percentage of null values would hardly make any difference in the EDA or the model creation and prediction\n"
     ]
    }
   ],
   "source": [
    "check_nulls(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_nulls(value):\n",
    "    if pd.isnull(value):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(value)\n",
    "    \n",
    "# Define a function to transform values\n",
    "def transform_time(value):\n",
    "    if isinstance(value, int):\n",
    "        value = str(value)  # Convert integer to string\n",
    "    value = value.zfill(4)  # Pad with leading zeros if necessary\n",
    "    if len(value) == 4:\n",
    "        if int(value) == 2400:\n",
    "            return '00:00'\n",
    "        if int(value) < 10:  # For values less than 10\n",
    "            return f'00:0{value[0]}'\n",
    "        elif int(value) < 100:  # For values between 10 and 100\n",
    "            return f'00:{value[:2]}'\n",
    "        else:  # For values over 100\n",
    "            return f'{value[:2]}:{value[2:]}'\n",
    "    else:\n",
    "        return value[:2] + ':' + value[2:]  # Format as 'HH:MM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dates():\n",
    "    data['FlightDate'] = pd.to_datetime(data['FlightDate'])\n",
    "\n",
    "    # Format time WheelsOff\n",
    "    data['WheelsOff'] = data['WheelsOff'].apply(treat_nulls)\n",
    "    data['WheelsOff'] = data['WheelsOff'].apply(transform_time)\n",
    "    data['WheelsOff'] = pd.to_datetime(data['WheelsOff'], format='%H:%M').dt.time\n",
    "\n",
    "    # Format time WheelsOn\n",
    "    data['WheelsOn'] = data['WheelsOn'].apply(treat_nulls)\n",
    "    data['WheelsOn'] = data['WheelsOn'].apply(transform_time)\n",
    "    data['WheelsOn'] = pd.to_datetime(data['WheelsOn'], format='%H:%M').dt.time\n",
    "\n",
    "    # Format time ArrTime\n",
    "    data['ArrTime'] = data['ArrTime'].apply(treat_nulls)\n",
    "    data['ArrTime'] = data['ArrTime'].apply(transform_time)\n",
    "    data['ArrTime'] = pd.to_datetime(data['ArrTime'], format='%H:%M').dt.time\n",
    "\n",
    "\n",
    "    # Format time DepTime\n",
    "    data['DepTime'] = data['DepTime'].apply(treat_nulls)\n",
    "    data['DepTime'] = data['DepTime'].apply(transform_time)\n",
    "    data['DepTime'] = pd.to_datetime(data['DepTime'], format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '11:40:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mformat_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[97], line 5\u001b[0m, in \u001b[0;36mformat_dates\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlightDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlightDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Format time WheelsOff\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWheelsOff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreat_nulls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(transform_time)\n\u001b[0;32m      7\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWheelsOff\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtime\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\series.py:4908\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[96], line 5\u001b[0m, in \u001b[0;36mtreat_nulls\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '11:40:00'"
     ]
    }
   ],
   "source": [
    "format_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m origins \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginAirportID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginAirportSeqID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginCityMarketID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrigin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginCityName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginState\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginStateFips\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginStateName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginWac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m origins\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m origins\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/processed/origins.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac'] not in index\""
     ]
    }
   ],
   "source": [
    "origins = data[['OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac']]\n",
    "origins.drop_duplicates(inplace=True)\n",
    "origins.to_csv('../data/processed/origins.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m destinations \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestAirportID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestAirportSeqID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestCityMarketID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestCityName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestState\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestStateFips\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestStateName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDestWac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m destinations\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m destinations\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/processed/destinations.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Documentos\\Cursos\\4geeks\\flight-status-prediction\\.env-flights\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac'] not in index\""
     ]
    }
   ],
   "source": [
    "destinations = data[['DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac']]\n",
    "destinations.drop_duplicates(inplace=True)\n",
    "destinations.to_csv('../data/processed/destinations.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['CRSDepTime','ActualElapsedTime','CRSArrTime', 'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac', 'TaxiIn', 'TaxiOut', 'ArrDel15', 'ArrivalDelayGroups', 'ArrTimeBlk', 'DistanceGroup', 'CRSDepTime', 'DepDel15', 'DepartureDelayGroups', 'DepTimeBlk', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'CRSArrTime', 'CRSElapsedTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FlightDate', 'Airline', 'Cancelled', 'Diverted', 'DepTime',\n",
      "       'DepDelayMinutes', 'DepDelay', 'ArrTime', 'ArrDelayMinutes', 'AirTime',\n",
      "       'CRSElapsedTime', 'Distance', 'Year', 'Quarter', 'Month', 'DayofMonth',\n",
      "       'DayOfWeek', 'Marketing_Airline_Network',\n",
      "       'Operated_or_Branded_Code_Share_Partners', 'DOT_ID_Marketing_Airline',\n",
      "       'IATA_Code_Marketing_Airline', 'Flight_Number_Marketing_Airline',\n",
      "       'Operating_Airline', 'DOT_ID_Operating_Airline',\n",
      "       'IATA_Code_Operating_Airline', 'Tail_Number',\n",
      "       'Flight_Number_Operating_Airline', 'OriginAirportID', 'DestAirportID',\n",
      "       'WheelsOff', 'WheelsOn', 'ArrDelay', 'DivAirportLandings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "colms = data.columns\n",
    "\n",
    "print(colms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/processed/Combined_Flights_2022.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4078318 entries, 0 to 4078317\n",
      "Data columns (total 34 columns):\n",
      " #   Column                                   Dtype  \n",
      "---  ------                                   -----  \n",
      " 0   Unnamed: 0                               int64  \n",
      " 1   FlightDate                               object \n",
      " 2   Airline                                  object \n",
      " 3   Cancelled                                bool   \n",
      " 4   Diverted                                 bool   \n",
      " 5   DepTime                                  object \n",
      " 6   DepDelayMinutes                          float64\n",
      " 7   DepDelay                                 float64\n",
      " 8   ArrTime                                  object \n",
      " 9   ArrDelayMinutes                          float64\n",
      " 10  AirTime                                  float64\n",
      " 11  CRSElapsedTime                           float64\n",
      " 12  Distance                                 float64\n",
      " 13  Year                                     int64  \n",
      " 14  Quarter                                  int64  \n",
      " 15  Month                                    int64  \n",
      " 16  DayofMonth                               int64  \n",
      " 17  DayOfWeek                                int64  \n",
      " 18  Marketing_Airline_Network                object \n",
      " 19  Operated_or_Branded_Code_Share_Partners  object \n",
      " 20  DOT_ID_Marketing_Airline                 int64  \n",
      " 21  IATA_Code_Marketing_Airline              object \n",
      " 22  Flight_Number_Marketing_Airline          int64  \n",
      " 23  Operating_Airline                        object \n",
      " 24  DOT_ID_Operating_Airline                 int64  \n",
      " 25  IATA_Code_Operating_Airline              object \n",
      " 26  Tail_Number                              object \n",
      " 27  Flight_Number_Operating_Airline          int64  \n",
      " 28  OriginAirportID                          int64  \n",
      " 29  DestAirportID                            int64  \n",
      " 30  WheelsOff                                object \n",
      " 31  WheelsOn                                 object \n",
      " 32  ArrDelay                                 float64\n",
      " 33  DivAirportLandings                       int64  \n",
      "dtypes: bool(2), float64(7), int64(13), object(12)\n",
      "memory usage: 1003.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/processed/Combined_Flights_2022.csv')\n",
    "origins = pd.read_csv('../data/processed/origins.csv')\n",
    "destinations = pd.read_csv('../data/processed/destinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'FlightDate', 'Airline', 'Cancelled', 'Diverted',\n",
       "       'DepTime', 'DepDelayMinutes', 'DepDelay', 'ArrTime', 'ArrDelayMinutes',\n",
       "       'AirTime', 'CRSElapsedTime', 'Distance', 'Year', 'Quarter', 'Month',\n",
       "       'DayofMonth', 'DayOfWeek', 'Marketing_Airline_Network',\n",
       "       'Operated_or_Branded_Code_Share_Partners', 'DOT_ID_Marketing_Airline',\n",
       "       'IATA_Code_Marketing_Airline', 'Flight_Number_Marketing_Airline',\n",
       "       'Operating_Airline', 'DOT_ID_Operating_Airline',\n",
       "       'IATA_Code_Operating_Airline', 'Tail_Number',\n",
       "       'Flight_Number_Operating_Airline', 'OriginAirportID', 'DestAirportID',\n",
       "       'WheelsOff', 'WheelsOn', 'ArrDelay', 'DivAirportLandings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a bussines perspective point of view I wouldn't impute null values, since, for example, DepTime might be null because the flight might have been cancelled and if we impute or drop that registry we might affect the future predictions or even the hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Database Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# load the .env file variables\n",
    "load_dotenv()\n",
    "\n",
    "# 1) Connect to the database here using the SQLAlchemy's create_engine function\n",
    "def conn_string():\n",
    "    user = os.getenv('DB_USER')\n",
    "    pwd = os.getenv('DB_PASSWORD')\n",
    "    host = os.getenv('DB_HOST')\n",
    "    db = os.getenv('DB_NAME')\n",
    "\n",
    "    return f\"postgresql://{user}:{pwd}@{host}/{db}\"\n",
    "\n",
    "def connect():\n",
    "    global engine\n",
    "    print(\"Starting connection...\")\n",
    "    engine = create_engine(conn_string()).execution_options(autocommit=True)\n",
    "    engine.connect()\n",
    "\n",
    "    return engine\n",
    "\n",
    "connect()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Define your dataset columns and their corresponding data types\n",
    "columns = {\n",
    "    'FlightDate': 'DATE',\n",
    "    'Airline': 'VARCHAR(255)',\n",
    "    'Origin': 'VARCHAR(255)',\n",
    "    # Define other columns and their data types here\n",
    "}\n",
    "\n",
    "# Generate SQL statement to create table\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE flights (\n",
    "    {\", \".join([f\"{col} {dtype}\" for col, dtype in columns.items()])}\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL statement to create table\n",
    "engine.execute(create_table_sql)\n",
    "\n",
    "# Now, let's say you have your data stored in a pandas DataFrame called 'df'\n",
    "# You can iterate over the DataFrame rows and generate SQL statements to insert data\n",
    "for index, row in df.iterrows():\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO flights ({\", \".join(columns.keys())}) VALUES \n",
    "    ({\", \".join([str(row[col]) for col in columns.keys()])});\n",
    "    \"\"\"\n",
    "    # Execute SQL statement to insert data\n",
    "    engine.execute(insert_sql)\n",
    "\n",
    "########################################################################\n",
    "\n",
    "# 4) Use pandas to print one of the tables as dataframes using read_sql function\n",
    "df = pd.read_sql('SELECT * FROM authors', engine)\n",
    "print(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load_dotenv()\n",
    "\n",
    "# 1) Connect to the database here using the SQLAlchemy's create_engine function\n",
    "def conn_string():\n",
    "    user = os.getenv('DB_USER')\n",
    "    pwd = os.getenv('DB_PASSWORD')\n",
    "    host = os.getenv('DB_HOST')\n",
    "    db = os.getenv('DB_NAME')\n",
    "\n",
    "    return f\"postgresql://{user}:{pwd}@{host}/{db}\"\n",
    "\n",
    "def connect():\n",
    "    global engine\n",
    "    print(\"Starting connection...\")\n",
    "    engine = create_engine(conn_string()).execution_options(autocommit=True)\n",
    "    engine.connect()\n",
    "\n",
    "    return engine\n",
    "\n",
    "connect()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition - Queries to obtain the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-flights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
